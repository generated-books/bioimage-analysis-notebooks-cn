{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ranging-theology",
   "metadata": {},
   "source": [
    "(lists-and-tuples)=\n",
    "# \u5217\u8868\u548c\u5143\u7ec4\n",
    "\u53d8\u91cf\u4e5f\u53ef\u4ee5\u5305\u542b\u591a\u4e2a\u503c\u7684\u6761\u76ee\u3002\u6211\u4eec\u79f0\u4e4b\u4e3a\u5217\u8868\u548c\u5143\u7ec4\u3002\u4e00\u4e9b\u7a0b\u5e8f\u5458\u4e5f\u79f0\u5b83\u4eec\u4e3a\u5411\u91cf\u6216\u6570\u7ec4\uff1b\u503c\u7684\u6570\u7ec4\u3002\u6211\u4eec\u5df2\u7ecf\u77e5\u9053\u4e00\u79cd\u6570\u7ec4\uff0c\u90a3\u5c31\u662f\u5b57\u7b26\u4e32\u3002\u5b57\u7b26\u4e32\u662f\u5b57\u7b26\u7684\u5217\u8868\u3002\n",
    "\n",
    "\u53e6\u8bf7\u53c2\u9605\n",
    "* [\u6570\u7ec4](https://physics.nyu.edu/pine/pymanual/html/chap3/chap3_arrays.html)\n",
    "* [\u5217\u8868\u5e73\u5747\u503c](https://www.geeksforgeeks.org/find-average-list-python/)\n",
    "* [Python\u4e2d\u7684\u6570\u7ec4](https://www.scaler.com/topics/array-in-python/)\n",
    "\n",
    "\u4f60\u53ef\u4ee5\u4f7f\u7528\u65b9\u62ec\u53f7 `[]` \u6765\u8bbf\u95ee\u6570\u7ec4\u4e2d\u7684\u5143\u7d20\uff0c\u8fd9\u5141\u8bb8\u4f60\u8bbf\u95ee\u7ed9\u5b9a\u7d22\u5f15\u5904\u7684\u5143\u7d20\u3002\u7d22\u5f15\u4ece0\u5f00\u59cb\u3002\u56e0\u6b64\uff0c\u6570\u7ec4\u7684\u7b2c\u4e00\u4e2a\u5143\u7d20\u662f\u7f16\u53f7\u4e3a0\u7684\u5143\u7d20\u3002\u4ee5\u4e0b\u5b57\u7b26\u4e32\u5305\u542b5\u4e2a\u5b57\u7b26\uff0c\u56e0\u6b64\u53ef\u4ee5\u8bbf\u95ee\u7d22\u5f15\u4e3a0\u30011\u30012\u30013\u548c4\u7684\u5143\u7d20\uff1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "divine-cartoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"Hello\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "mental-height",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'H'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "medical-beverage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "collected-cleaning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'l'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "honest-tribe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'l'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "electronic-sauce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'o'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12b60fa-fc21-4240-9f35-dc7ba84f050b",
   "metadata": {},
   "source": [
    "\u5f53\u8bbf\u95ee\u4e0d\u5728\u5217\u8868\u4e2d\u7684\u7d22\u5f15\u65f6\uff0c\u6211\u4eec\u4f1a\u6536\u5230\u9519\u8bef\uff1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "former-balloon",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mword\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "word[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-therapist",
   "metadata": {},
   "source": [
    "# \u6570\u503c\u5217\u8868\n",
    "\u53e6\u4e00\u79cd\u7c7b\u578b\u7684\u6570\u7ec4\u662f\u6570\u503c\u5217\u8868\u3002\u5b83\u4eec\u901a\u5e38\u7528\u4e8e\u5b58\u50a8\u5b9e\u9a8c\u6d4b\u91cf\u503c\uff0c\u4f8b\u5982\uff1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "critical-hearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements = [5.5, 6.3, 7.2, 8.0, 8.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "presidential-brush",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measurements[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sweet-munich",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measurements[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "military-vision",
   "metadata": {},
   "source": [
    "\u66f4\u6539\u5217\u8868\u4e2d\u7684\u6761\u76ee\u53ef\u4ee5\u8fd9\u6837\u505a\uff1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "hairy-tomato",
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements[1] = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "usual-leeds",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measurements[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "antique-collins",
   "metadata": {},
   "source": [
    "\u4f60\u4e5f\u53ef\u4ee5\u5411\u5217\u8868\u6dfb\u52a0\u6761\u76ee\uff1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "multiple-coffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements.append(10.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moved-consultation",
   "metadata": {},
   "source": [
    "\u5217\u8868\u4e5f\u53ef\u4ee5\u53cd\u8f6c\uff1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fitting-december",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.5, 25, 7.2, 8.0, 8.8, 10.2]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "literary-designation",
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "united-joint",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10.2, 8.8, 8.0, 7.2, 25, 5.5]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "periodic-toyota",
   "metadata": {},
   "source": [
    "\u5c31\u50cf\u5b57\u7b26\u4e32\u4e00\u6837\uff0c\u4f60\u4e5f\u53ef\u4ee5\u8fde\u63a5\u6570\u7ec4\uff1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "gorgeous-harbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "more_measurements = [12.3, 14.5, 28.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "latest-rachel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10.2, 8.8, 8.0, 7.2, 25, 5.5, 12.3, 14.5, 28.3]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measurements + more_measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-literature",
   "metadata": {},
   "source": [
    "\u5728\u5904\u7406\u6570\u503c\u5217\u8868\u65f6\uff0c\u4f60\u53ef\u4ee5\u4f7f\u7528Python\u7684\u4e00\u4e9b\u5185\u7f6e\u51fd\u6570\u5bf9\u4f60\u7684\u6d4b\u91cf\u503c\u8fdb\u884c\u57fa\u672c\u7edf\u8ba1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "entitled-incident",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \u5217\u8868\u4e2d\u7684\u6700\u5c0f\u503c\n",
    "min(measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "checked-factor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \u5217\u8868\u4e2d\u7684\u6700\u5927\u503c\n",
    "max(measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "irish-space",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.7"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \u5217\u8868\u4e2d\u6240\u6709\u5143\u7d20\u7684\u548c\n",
    "sum(measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "established-school",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \u5217\u8868\u4e2d\u7684\u5143\u7d20\u6570\u91cf\n",
    "len(measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "spectacular-blocking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.783333333333333"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \u5217\u8868\u4e2d\u6240\u6709\u5143\u7d20\u7684\u5e73\u5747\u503c\n",
    "sum(measurements) / len(measurements)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "favorite-canvas",
   "metadata": {},
   "source": [
    "# \u6df7\u5408\u7c7b\u578b\u5217\u8868\n",
    "\u4f60\u4e5f\u53ef\u4ee5\u5728\u5217\u8868\u4e2d\u5b58\u50a8\u4e0d\u540c\u7c7b\u578b\u7684\u503c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "chief-people",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_list = [22, 5.6, \"Cat\", 'Dog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "listed-shape",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixed_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "exclusive-correction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dog'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixed_list[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "geographic-allah",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mixed_list[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-naples",
   "metadata": {},
   "source": [
    "# \u5143\u7ec4\n",
    "\u5143\u7ec4\u662f\u4e0d\u80fd\u6539\u53d8\u7684\u5217\u8868\uff1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ambient-institution",
   "metadata": {},
   "outputs": [],
   "source": [
    "immutable = (4, 3, 7.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "careful-shell",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immutable[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "confused-sympathy",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m immutable[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "immutable[1] = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civic-cameroon",
   "metadata": {},
   "source": [
    "\u4f60\u53ef\u4ee5\u5c06\u5143\u7ec4\u8f6c\u6362\u4e3a\u5217\u8868\uff0c\u4e5f\u53ef\u4ee5\u5c06\u5217\u8868\u8f6c\u6362\u4e3a\u5143\u7ec4\uff1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "stone-continuity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(immutable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "equal-european",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable = list(immutable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "turned-cemetery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mutable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "upset-bandwidth",
   "metadata": {},
   "outputs": [],
   "source": [
    "again_immuntable = tuple(mutable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "tested-contrary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(again_immuntable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supreme-proceeding",
   "metadata": {},
   "source": [
    "# \u7ec3\u4e60\n",
    "\u5047\u8bbe\u4f60\u5728\u591a\u5929\u8fdb\u884c\u4e86\u6d4b\u91cf\u3002\u8ba1\u7b97\u672c\u5468\u7684\u5e73\u5747\u6d4b\u91cf\u503c\uff1f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "sublime-unemployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements_monday = [2.3, 3.1, 5.6]\n",
    "measurements_tuesday = [1.8, 7.0]\n",
    "measurements_wednesday = [4.5, 1.5, 6.4, 3.2]\n",
    "measurements_thursday = [1.9, 2.0]\n",
    "measurements_friday = [4.4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-stage",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}